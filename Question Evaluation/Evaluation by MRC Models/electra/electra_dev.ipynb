{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a688028f-fc44-4949-bda0-340bb42fcd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "'''import libraries used, json to read the data, \n",
    "randint for randomly generated paragraphs, \n",
    "and pandas to create a dataframe to be written to csv'''\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import csv\n",
    "fname = 'dev-SQuAD-v2.0'\n",
    "f = open(fname + '.json')\n",
    "#load in data as python dictionary using the json library\n",
    "data = json.load(f)\n",
    "data = data[\"data\"]\n",
    "samples = pd.read_csv(\"Negation_dev.csv\")\n",
    "originals = pd.read_csv(\"dev_start.csv\")\n",
    "originals = originals.drop('New_Context', axis=1)\n",
    "originals.drop(originals.columns[originals.columns.str.contains(\n",
    "    'unnamed', case=False)], axis=1, inplace=True)\n",
    "electra = pipeline(\"question-answering\", model=\"deepset/electra-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8998c01d-09b3-439c-805f-1c18ef7a44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    final = pd.read_csv(\"Task13P-U-dev.csv\").to_dict('records')\n",
    "except:\n",
    "    final = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc04299-9cb0-43d5-ab98-af470e0620a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_output = \"Task13P-U-dev.tsv\"\n",
    "record_file = open(address_output, \"w\")  ## this is 'w' = write mode\n",
    "tsv_writer_temp = csv.writer(record_file, delimiter='\\t', lineterminator='\\n')\n",
    "tsv_writer_temp.writerow(['Question_Id', 'Context', 'Original_Question', 'Original_Answer', 'Modified_Question', 'O-Q model2 answer span', 'O-Q model2 start', 'O-Q model2 end', 'O-Q model2 score', 'O-Q model4 answer span', 'O-Q model4 start', 'O-Q model4 end', 'O-Q model4 score', 'O-Q electra answer span', 'O-Q electra start', 'O-Q electra end', 'O-Q electra score', 'O-Q roberta answer span', 'O-Q roberta start', 'O-Q roberta end', 'O-Q roberta score', 'O-Q albert score', 'O-Q albert answer span', 'O-Q sgnet answer span', 'O-Q retro answer span', 'P-U model2 answer span', 'P-U model2 start', 'P-U model2 end', 'P-U model2 score', 'P-U model4 answer span', 'P-U model4 start', 'P-U model4 end', 'P-U model4 score', 'P-U electra answer span', 'P-U electra start', 'P-U electra end', 'P-U electra score', 'P-U roberta answer span', 'P-U roberta start', 'P-U roberta end', 'P-U roberta score', 'P-U albert score'])\n",
    "record_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e204f7e0-8db4-4825-981c-84048ec19bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#odata = json.load(open(\"SGO.json\"))\n",
    "#odata = [json.load(open(\"albert0.json\")), json.load(open(\"SGO.json\")), json.load(open(\"retrospective.json\"))]\n",
    "def get_output_models(id, question, context):\n",
    "    row = {}\n",
    "    \n",
    "    preds = electra(question=question, context=context,)\n",
    "    row[\"P-U electra answer span\"] = preds[\"answer\"]\n",
    "    row[\"P-U electra start\"] = preds[\"start\"]\n",
    "    row[\"P-U electra end\"] = preds[\"end\"]\n",
    "    row[\"P-U electra score\"] = preds[\"score\"]\n",
    "    #row[\"P-U \" + labels[i + 1] + \" answer span\"] = odata[id] \n",
    "    #for j in range(0, len(odata)):\n",
    "#        row[\"P-U \" + labels[i + j] + \" answer span\"] = odata[j][id]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ad1ebf-a6a5-41b4-bee5-49addb61a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(df):\n",
    "    final_df = pd.DataFrame(final)\n",
    "    final_df.to_csv(\"Task13P-U-dev.csv\")\n",
    "\n",
    "def append_row(row):\n",
    "    with open(\"Task13P-U-dev.tsv\",'a', encoding='utf-8') as f1: ## this is 'a' = apend mode\n",
    "        writer=csv.writer(f1, delimiter='\\t',lineterminator='\\n',)\n",
    "        nrow = []\n",
    "        for k, v in row.items():\n",
    "            nrow.append(v)\n",
    "        writer.writerow(nrow) # These are the value for the new row in df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51111497-6019-4932-a30f-bf362180f52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Different topics:   0%|                                                                         | 0/35 [00:00<?, ?it/s]\n",
      "Going through paragraphs:   0%|                                                                 | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Going through paragraphs:  69%|██████████████████████████████████████                 | 27/39 [00:00<00:00, 258.79it/s]\u001b[A\n",
      "Different topics:   3%|█▊                                                               | 1/35 [00:00<00:05,  6.14it/s]\u001b[A\n",
      "Going through paragraphs:   0%|                                                                 | 0/48 [00:00<?, ?it/s]\u001b[A\n",
      "Going through paragraphs:  38%|████████████████████▋                                  | 18/48 [00:00<00:00, 175.55it/s]\u001b[A\n",
      "Going through paragraphs:  75%|█████████████████████████████████████████▎             | 36/48 [00:00<00:00, 166.24it/s]\u001b[A\n",
      "Different topics:   6%|███▋                                                             | 2/35 [00:00<00:08,  3.92it/s]\u001b[A\n",
      "Going through paragraphs:   0%|                                                                 | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Going through paragraphs:  33%|██████████████████▎                                    | 13/39 [00:00<00:00, 127.32it/s]\u001b[A\n",
      "Going through paragraphs:  67%|████████████████████████████████████▋                  | 26/39 [00:00<00:00, 126.59it/s]\u001b[A\n",
      "Different topics:   9%|█████▌                                                           | 3/35 [00:00<00:08,  3.66it/s]\u001b[A\n",
      "Going through paragraphs:   0%|                                                                 | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Going through paragraphs:  68%|█████████████████████████████████████▌                 | 15/22 [00:00<00:00, 144.04it/s]\u001b[A\n",
      "Different topics:  11%|███████▍                                                         | 4/35 [00:00<00:07,  4.29it/s]\u001b[A\n",
      "Going through paragraphs:   0%|                                                                 | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "Going through paragraphs:  48%|██████████████████████████▍                            | 12/25 [00:00<00:00, 113.79it/s]\u001b[A\n",
      "Different topics:  14%|█████████▎                                                       | 5/35 [00:01<00:06,  4.43it/s]\u001b[A\n",
      "Going through paragraphs:   0%|                                                                 | 0/44 [00:00<?, ?it/s]\u001b[A\n",
      "Going through paragraphs:  25%|█████████████▊                                         | 11/44 [00:00<00:00, 108.75it/s]\u001b[A\n",
      "Going through paragraphs:  25%|█████████████▊                                         | 11/44 [00:18<00:00, 108.75it/s]\u001b[A\n",
      "Going through paragraphs:  48%|██████████████████████████▋                             | 21/44 [00:48<01:03,  2.76s/it]\u001b[A\n",
      "Going through paragraphs:  50%|████████████████████████████                            | 22/44 [01:15<01:39,  4.54s/it]\u001b[A\n",
      "Going through paragraphs:  52%|█████████████████████████████▎                          | 23/44 [01:46<02:28,  7.05s/it]\u001b[A\n",
      "Going through paragraphs:  55%|██████████████████████████████▌                         | 24/44 [02:10<03:03,  9.19s/it]\u001b[A\n",
      "Going through paragraphs:  57%|███████████████████████████████▊                        | 25/44 [02:29<03:22, 10.64s/it]\u001b[A\n",
      "Going through paragraphs:  59%|█████████████████████████████████                       | 26/44 [02:58<04:06, 13.71s/it]\u001b[A\n",
      "Going through paragraphs:  61%|██████████████████████████████████▎                     | 27/44 [03:22<04:29, 15.83s/it]\u001b[A\n",
      "Going through paragraphs:  64%|███████████████████████████████████▋                    | 28/44 [03:46<04:42, 17.65s/it]\u001b[A\n",
      "Going through paragraphs:  66%|████████████████████████████████████▉                   | 29/44 [04:25<05:40, 22.71s/it]\u001b[A\n",
      "Going through paragraphs:  68%|██████████████████████████████████████▏                 | 30/44 [04:54<05:41, 24.39s/it]\u001b[A\n",
      "Going through paragraphs:  70%|███████████████████████████████████████▍                | 31/44 [05:18<05:15, 24.25s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "#this is the dataframe that will be converted to pandas and then to csv\n",
    "#final = []\n",
    "#counter = 0\n",
    "#loop through all different data titles/topics associated!\n",
    "for i in tqdm(range(len(data)), desc=\"Different topics: \"):\n",
    "    #get number of paragraphs per topic\n",
    "    length = len(data[i]['paragraphs'])\n",
    "    #get list of all paragraphs for later use\n",
    "    paragraphs = data[i]['paragraphs']\n",
    "    #loop through each paragraph\n",
    "    for j in tqdm(range(len(paragraphs)), leave=False, desc=\"Going through paragraphs: \"):\n",
    "        #get all of the questions associated per paragraph\n",
    "        questions = paragraphs[j]['qas']\n",
    "        #get the context paragraph value\n",
    "        context = paragraphs[j]['context']\n",
    "        #loop through all questions in each topic paragraph\n",
    "        for k in range(0, len(questions)):\n",
    "            if(questions[k]['is_impossible'] == False):\n",
    "                #get the question id\n",
    "                id = questions[k]['id']\n",
    "                if not any(d['Question_Id'] == id for d in final):\n",
    "                    #get question value\n",
    "                    question = questions[k]['question']\n",
    "                    answer = questions[k][\"answers\"][0][\"text\"]\n",
    "                    relevant_pot_qs = samples.loc[samples['Question_Id'] == id]\n",
    "                    for index, row in relevant_pot_qs.iterrows():\n",
    "                        frow = originals.loc[originals['Question_Id'] == id]\n",
    "                        final_row = frow.to_dict('records')[0]\n",
    "                        #final_row = {\"Question_ID\": id,  \"Context\": context, \"Original_Question\": question, \"Original_Answer\": answer, \"Modified_Question\": row[\"Modified_Question\"]}\n",
    "                        #for k, v in get_og_ans(id).items():\n",
    "                        #    final_row[k] = v\n",
    "                        for k, v in get_output_models(id, str(row[\"Modified_Question\"]), context).items():\n",
    "                            final_row[k] = v\n",
    "                        #print(final_row)\n",
    "                        final.append(final_row)\n",
    "                        append_row(final_row)\n",
    "                        save_csv(final)\n",
    "                else:\n",
    "                    used_id = [d for d in final if d.get('Question_Id') == id]\n",
    "                    length = len(used_id)\n",
    "                    used_originals = originals.loc[originals['Question_Id'] == id]\n",
    "                    olen = used_originals.shape[0]\n",
    "                    if(length < olen):\n",
    "                        final = final.loc[final['Question_Id'] != id]\n",
    "                        #get question value\n",
    "                        question = questions[k]['question']\n",
    "                        answer = questions[k][\"answers\"][0][\"text\"]\n",
    "                        relevant_pot_qs = samples.loc[samples['Question_Id'] == id]\n",
    "                        for index, row in relevant_pot_qs.iterrows():\n",
    "                            frow = originals.loc[originals['Question_Id'] == id]\n",
    "                            final_row = frow.to_dict('records')[0]\n",
    "                            #final_row = {\"Question_ID\": id,  \"Context\": context, \"Original_Question\": question, \"Original_Answer\": answer, \"Modified_Question\": row[\"Modified_Question\"]}\n",
    "                            #for k, v in get_og_ans(id).items():\n",
    "                            #    final_row[k] = v\n",
    "                            for k, v in get_output_models(id, str(row[\"Modified_Question\"]), context).items():\n",
    "                                final_row[k] = v\n",
    "                            #print(final_row)\n",
    "                            final.append(final_row)\n",
    "                            append_row(final_row)\n",
    "                            save_csv(final)\n",
    "                        \n",
    "                    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a0ee7-eeac-467e-96e3-210ac9c7a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e8f9f-fda5-4b1a-af92-c00369270466",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c868a989-650a-4701-a992-003a574a4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"Task13P-U-dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8552164-1a4e-4002-ab6c-2110789443b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe433e-5e3e-4e21-8f9d-a9a150aec37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66bdef7-75e1-4ae0-80c8-3ac6b0b1ec17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
